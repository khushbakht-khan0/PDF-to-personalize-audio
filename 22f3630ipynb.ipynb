{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb3L8ig-SqGA"
      },
      "outputs": [],
      "source": [
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "fo0qFow0Swy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import pathlib\n",
        "import requests\n",
        "import pdfplumber\n",
        "\n",
        "API_KEY = \"c59d7647f50ca3f4ffca47e99a5959ab7033f688\"\n",
        "MODEL = \"aura-3-thalia-en\"\n",
        "PDF_PATH = \"life3.0.pdf\"\n",
        "\n",
        "# Extract text from PDF\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            if page_text := page.extract_text():\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Split text into manageable chunks\n",
        "def chunk_text(text, max_len=2000):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    chunks, current = [], \"\"\n",
        "    for s in sentences:\n",
        "        if len(current) + len(s) < max_len:\n",
        "            current = (current + \" \" + s).strip()\n",
        "        else:\n",
        "            if current:\n",
        "                chunks.append(current)\n",
        "            current = s\n",
        "    if current:\n",
        "        chunks.append(current)\n",
        "    return chunks\n",
        "\n",
        "# Convert text chunk to speech\n",
        "def tts_chunk(chunk, idx):\n",
        "    url = \"https://api.deepgram.com/v1/speak\"\n",
        "    headers = {\"Authorization\": f\"Token {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(url, params={\"model\": MODEL}, headers=headers, json={\"text\": chunk})\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error {response.status_code}: {response.text}\")\n",
        "        return None\n",
        "\n",
        "    filename = f\"audio_{idx:03d}.mp3\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"Saved {filename}\")\n",
        "    return filename\n",
        "\n",
        "def main():\n",
        "    text = extract_text_from_pdf(PDF_PATH)\n",
        "    parts = []\n",
        "\n",
        "    for i, chunk in enumerate(chunk_text(text), start=1):\n",
        "        filename = tts_chunk(chunk, i)\n",
        "        if filename:\n",
        "            parts.append(filename)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    with open(\"parts.txt\", \"w\") as f:\n",
        "        for p in parts:\n",
        "            f.write(f\"file '{pathlib.Path(p).as_posix()}'\\n\")\n",
        "\n",
        "    print(\"\\nâœ… All chunks processed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "J3xN-G1jS3ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/OpenVoice/cloned_chunks\"\n",
        "merge_list = os.path.join(output_dir, \"file_list.txt\")\n",
        "merged_file = \"/content/drive/MyDrive/OpenVoice/merged_50.mp3\"\n",
        "\n",
        "# Create the file list for ffmpeg\n",
        "with open(merge_list, \"w\") as f:\n",
        "    for idx in range(50):  # first 50 chunks only\n",
        "        file_path = os.path.join(output_dir, f\"audio_{idx:03d}.mp3\")\n",
        "        f.write(f\"file '{file_path}'\\n\")\n",
        "\n",
        "# Run ffmpeg merge\n",
        "subprocess.run([\n",
        "    \"ffmpeg\",\n",
        "    \"-y\",\n",
        "    \"-f\", \"concat\",\n",
        "    \"-safe\", \"0\",\n",
        "    \"-i\", merge_list,\n",
        "    \"-c\", \"copy\",\n",
        "    merged_file\n",
        "])"
      ],
      "metadata": {
        "id": "JzENoBk4TmTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone OpenVoice repository if not exists\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "openvoice_dir = Path(\"/content/OpenVoice\")\n",
        "if not openvoice_dir.exists():\n",
        "    !git clone https://github.com/myshell-ai/OpenVoice.git {openvoice_dir}\n",
        "\n",
        "%cd {openvoice_dir}"
      ],
      "metadata": {
        "id": "OeOkuhttT6AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q unidecode eng_to_ipa inflect pypinyin jieba cn2an \\\n",
        "               librosa pyworld gradio ffmpeg-python faster_whisper \\\n",
        "               whisper_timestamped wavmark pydub"
      ],
      "metadata": {
        "id": "q6LDtWXOUu9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_dir = openvoice_dir / \"assets/converter_ckpt\"\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "!wget -q -O {ckpt_dir}/config.json https://huggingface.co/myshell-ai/OpenVoice/resolve/main/checkpoints/converter/config.json\n",
        "!wget -q -O {ckpt_dir}/weights.pth https://huggingface.co/myshell-ai/OpenVoice/resolve/main/checkpoints/converter/checkpoint.pth\n"
      ],
      "metadata": {
        "id": "iI1EYDXVUyif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Add OpenVoice path to Python path\n",
        "import sys\n",
        "sys.path.append(str(openvoice_dir / \"OpenVoice\"))\n",
        "\n",
        "# Mount Google Drive and define file paths\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ref_clip    = \"/content/drive/MyDrive/OpenVoice/myvoice.m4a\"   # Reference voice\n",
        "input_file  = \"/content/drive/MyDrive/OpenVoice/life3_ai.mp3\"  # Input audio\n",
        "output_file = \"/content/drive/MyDrive/OpenVoice/final_cloned.wav\"  # Output cloned audio\n",
        "\n",
        "# Load ToneColorConverter model\n",
        "import torch\n",
        "from openvoice.api import ToneColorConverter\n",
        "from openvoice import se_extractor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "converter = ToneColorConverter(str(ckpt_dir / \"config.json\"), device=device)\n",
        "converter.load_ckpt(str(ckpt_dir / \"weights.pth\"))\n",
        "\n",
        "# Extract speaker embedding from reference clip\n",
        "target_se, _ = se_extractor.get_se(ref_clip, converter)\n",
        "\n",
        "# Convert full audio to cloned voice\n",
        "converter.convert(\n",
        "    audio_src_path=input_file,\n",
        "    src_se=None,\n",
        "    tgt_se=target_se,\n",
        "    output_path=output_file\n",
        ")\n",
        "\n",
        "print(f\"ðŸŽ‰ Done! Cloned audio saved at: {output_file}\")"
      ],
      "metadata": {
        "id": "8YBf3iv_UxYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}